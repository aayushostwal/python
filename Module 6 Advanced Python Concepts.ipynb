{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Advanced Python Concepts\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "Your application needs to:\n",
    "- Process millions of records using all CPU cores\n",
    "- Download 1000 files from an API without waiting sequentially\n",
    "- Ensure database connections are always properly closed, even when errors occur\n",
    "\n",
    "### The Goal\n",
    "\n",
    "By the end of this module, you will:\n",
    "- Use **multiprocessing** for CPU-bound parallelism\n",
    "- Use **threading** for I/O-bound concurrency\n",
    "- Master **asyncio** for high-concurrency applications\n",
    "- Write **context managers** for safe resource handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: Multiprocessing (True Parallelism)\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You need to process 10 million records. Your 8-core CPU sits at 12% usage because Python's GIL prevents true parallelism with threads.\n",
    "\n",
    "### The \"Aha!\" Moment\n",
    "\n",
    "Each **process** has its own Python interpreter and GIL. Multiprocessing bypasses the GIL entirely!\n",
    "\n",
    "### When to Use\n",
    "\n",
    "| Use Multiprocessing | Use Threading |\n",
    "|---------------------|---------------|\n",
    "| CPU-bound (math, processing) | I/O-bound (network, disk) |\n",
    "| Need true parallelism | Need shared memory |\n",
    "| Independent tasks | Lightweight concurrency |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU cores available: 10\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "import os\n",
    "\n",
    "def cpu_intensive(n):\n",
    "    \"\"\"Simulate CPU-heavy work.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 2\n",
    "    return total\n",
    "\n",
    "# Show available cores\n",
    "print(f\"CPU cores available: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential: 0.63s\n"
     ]
    }
   ],
   "source": [
    "# Sequential processing\n",
    "COUNT = 5_000_000\n",
    "\n",
    "start = time.perf_counter()\n",
    "results = [cpu_intensive(COUNT) for _ in range(4)]\n",
    "seq_time = time.perf_counter() - start\n",
    "print(f\"Sequential: {seq_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel (4 processes): 0.35s\n",
      "Speedup: 1.80x\n"
     ]
    }
   ],
   "source": [
    "# Parallel with Pool\n",
    "# Note: This may not show speedup in Jupyter due to how notebooks handle processes\n",
    "# Run as a script for accurate timing\n",
    "mp.set_start_method('fork', force=True)\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    with mp.Pool(processes=4) as pool:\n",
    "        results = pool.map(cpu_intensive, [COUNT] * 4)\n",
    "    \n",
    "    parallel_time = time.perf_counter() - start\n",
    "    print(f\"Parallel (4 processes): {parallel_time:.2f}s\")\n",
    "    print(f\"Speedup: {seq_time / parallel_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing Patterns\n",
    "\n",
    "| Pattern | Use Case | Example |\n",
    "|---------|----------|--------|\n",
    "| `Pool.map()` | Apply function to list | `pool.map(fn, items)` |\n",
    "| `Pool.starmap()` | Multiple arguments | `pool.starmap(fn, [(a,b), (c,d)])` |\n",
    "| `Process` | Manual control | `p = Process(target=fn)` |\n",
    "| `Queue` | Share data between processes | `q.put(data)` / `q.get()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from workers: [6, 15, 24]\n",
      "Total: 45\n"
     ]
    }
   ],
   "source": [
    "# Process with Queue for communication\n",
    "def worker(queue, data):\n",
    "    \"\"\"Worker that puts result in queue.\"\"\"\n",
    "    result = sum(data)\n",
    "    queue.put(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = mp.Queue()\n",
    "    data_chunks = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "    \n",
    "    processes = []\n",
    "    for chunk in data_chunks:\n",
    "        p = mp.Process(target=worker, args=(queue, chunk))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Collect results\n",
    "    results = [queue.get() for _ in processes]\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(f\"Results from workers: {results}\")\n",
    "    print(f\"Total: {sum(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 2: Threading (I/O Concurrency)\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You need to download 100 files from an API. Each request takes 1 second. Sequential = 100 seconds. Can we do better?\n",
    "\n",
    "### The \"Aha!\" Moment\n",
    "\n",
    "The GIL is released during I/O operations! While one thread waits for a network response, others can run.\n",
    "\n",
    "### Threading vs Multiprocessing\n",
    "\n",
    "| Aspect | Threading | Multiprocessing |\n",
    "|--------|-----------|----------------|\n",
    "| Memory | Shared | Isolated |\n",
    "| Overhead | Low | High |\n",
    "| GIL | Blocks CPU work | Bypassed |\n",
    "| Best for | I/O-bound | CPU-bound |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def download_file(file_id):\n",
    "    \"\"\"Simulate downloading a file (I/O-bound).\"\"\"\n",
    "    time.sleep(0.5)  # Simulate network latency\n",
    "    return f\"file_{file_id}.txt\"\n",
    "\n",
    "# Sequential downloads\n",
    "start = time.perf_counter()\n",
    "results = [download_file(i) for i in range(6)]\n",
    "seq_time = time.perf_counter() - start\n",
    "print(f\"Sequential: {seq_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threaded downloads\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    results = list(executor.map(download_file, range(6)))\n",
    "\n",
    "thread_time = time.perf_counter() - start\n",
    "print(f\"Threaded: {thread_time:.2f}s\")\n",
    "print(f\"Speedup: {seq_time / thread_time:.2f}x\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread safety with Lock\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment_unsafe():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1  # Race condition!\n",
    "\n",
    "def increment_safe():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "# Demonstrate race condition\n",
    "counter = 0\n",
    "threads = [threading.Thread(target=increment_unsafe) for _ in range(2)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()\n",
    "print(f\"Unsafe counter (expected 200000): {counter}\")\n",
    "\n",
    "# With lock\n",
    "counter = 0\n",
    "threads = [threading.Thread(target=increment_safe) for _ in range(2)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()\n",
    "print(f\"Safe counter (expected 200000): {counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThreadPoolExecutor Methods\n",
    "\n",
    "| Method | Use Case | Returns |\n",
    "|--------|----------|--------|\n",
    "| `map(fn, items)` | Apply to iterable | Iterator of results |\n",
    "| `submit(fn, *args)` | Single task | Future object |\n",
    "| `future.result()` | Get result | Blocks until done |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 3: AsyncIO (Event Loop Concurrency)\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Threading works for I/O, but 1000 threads is too many. Each thread uses ~8MB of stack space.\n",
    "\n",
    "### The \"Aha!\" Moment\n",
    "\n",
    "AsyncIO uses **cooperative multitasking** in a single thread. Coroutines voluntarily yield control at `await` points, allowing thousands of concurrent tasks with minimal overhead.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| `async def` | Define a coroutine function |\n",
    "| `await` | Pause and yield control |\n",
    "| Event Loop | Scheduler that runs coroutines |\n",
    "| Task | Scheduled coroutine |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data(item_id):\n",
    "    \"\"\"Simulate async I/O operation.\"\"\"\n",
    "    print(f\"Starting fetch {item_id}\")\n",
    "    await asyncio.sleep(1)  # Non-blocking sleep\n",
    "    print(f\"Completed fetch {item_id}\")\n",
    "    return f\"data_{item_id}\"\n",
    "\n",
    "# Run single coroutine\n",
    "result = await fetch_data(1)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple coroutines concurrently\n",
    "async def fetch_all():\n",
    "    tasks = [fetch_data(i) for i in range(5)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "start = time.perf_counter()\n",
    "results = await fetch_all()\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nAll results: {results}\")\n",
    "print(f\"Total time: {elapsed:.2f}s (not 5s!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async context manager for resources\n",
    "class AsyncDatabase:\n",
    "    async def __aenter__(self):\n",
    "        print(\"Connecting to database...\")\n",
    "        await asyncio.sleep(0.1)  # Simulate connection\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(\"Closing database connection...\")\n",
    "        await asyncio.sleep(0.1)\n",
    "    \n",
    "    async def query(self, sql):\n",
    "        await asyncio.sleep(0.1)\n",
    "        return f\"Result for: {sql}\"\n",
    "\n",
    "async def main():\n",
    "    async with AsyncDatabase() as db:\n",
    "        result = await db.query(\"SELECT * FROM users\")\n",
    "        print(result)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AsyncIO Patterns\n",
    "\n",
    "| Pattern | Use Case | Example |\n",
    "|---------|----------|--------|\n",
    "| `gather(*coros)` | Run concurrently, wait for all | `await gather(a(), b())` |\n",
    "| `create_task(coro)` | Schedule without waiting | `task = create_task(fn())` |\n",
    "| `wait_for(coro, timeout)` | With timeout | `await wait_for(fn(), 5.0)` |\n",
    "| `as_completed(coros)` | Process as they finish | `for coro in as_completed(...)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results as they complete\n",
    "async def fetch_with_delay(item_id, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    return f\"item_{item_id}\"\n",
    "\n",
    "async def process_as_completed():\n",
    "    tasks = [\n",
    "        fetch_with_delay(1, 0.3),\n",
    "        fetch_with_delay(2, 0.1),\n",
    "        fetch_with_delay(3, 0.2),\n",
    "    ]\n",
    "    \n",
    "    for coro in asyncio.as_completed(tasks):\n",
    "        result = await coro\n",
    "        print(f\"Got: {result}\")\n",
    "\n",
    "await process_as_completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson 4: Context Managers\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You open a file, process it, but an exception occurs before you close it. The file handle leaks.\n",
    "\n",
    "### The \"Aha!\" Moment\n",
    "\n",
    "Context managers guarantee cleanup code runs, even if exceptions occur. The `with` statement handles `__enter__` and `__exit__` automatically.\n",
    "\n",
    "### Common Built-in Context Managers\n",
    "\n",
    "| Context Manager | Purpose |\n",
    "|-----------------|--------|\n",
    "| `open(file)` | File handling |\n",
    "| `threading.Lock()` | Thread synchronization |\n",
    "| `contextlib.suppress(exc)` | Ignore specific exceptions |\n",
    "| `decimal.localcontext()` | Temporary decimal settings |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without context manager (dangerous!)\n",
    "# f = open('file.txt')\n",
    "# data = f.read()  # If this fails, file never closes!\n",
    "# f.close()\n",
    "\n",
    "# With context manager (safe!)\n",
    "# with open('file.txt') as f:\n",
    "#     data = f.read()  # File closes even if exception occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a context manager with class\n",
    "class Timer:\n",
    "    \"\"\"Context manager to time code blocks.\"\"\"\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.elapsed = time.perf_counter() - self.start\n",
    "        print(f\"Elapsed: {self.elapsed:.4f}s\")\n",
    "        return False  # Don't suppress exceptions\n",
    "\n",
    "# Usage\n",
    "with Timer():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Doing work...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a context manager with @contextmanager decorator\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer():\n",
    "    \"\"\"Simpler way to create context managers.\"\"\"\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        yield  # Code inside 'with' block runs here\n",
    "    finally:\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"Elapsed: {elapsed:.4f}s\")\n",
    "\n",
    "with timer():\n",
    "    time.sleep(0.3)\n",
    "    print(\"Working...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Database transaction\n",
    "@contextmanager\n",
    "def transaction(connection):\n",
    "    \"\"\"Ensure transaction commits or rolls back.\"\"\"\n",
    "    try:\n",
    "        yield connection\n",
    "        connection.commit()\n",
    "        print(\"Transaction committed\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Transaction rolled back: {e}\")\n",
    "        raise\n",
    "\n",
    "# Mock connection for demo\n",
    "class MockConnection:\n",
    "    def commit(self): pass\n",
    "    def rollback(self): pass\n",
    "    def execute(self, sql): print(f\"Executing: {sql}\")\n",
    "\n",
    "conn = MockConnection()\n",
    "with transaction(conn) as c:\n",
    "    c.execute(\"INSERT INTO users VALUES (1, 'Alice')\")\n",
    "    c.execute(\"UPDATE accounts SET balance = 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful contextlib utilities\n",
    "from contextlib import suppress, redirect_stdout\n",
    "from io import StringIO\n",
    "\n",
    "# suppress - ignore specific exceptions\n",
    "with suppress(FileNotFoundError):\n",
    "    # This won't raise an error\n",
    "    open('nonexistent_file.txt')\n",
    "print(\"Continued after suppressed error\")\n",
    "\n",
    "# redirect_stdout - capture print output\n",
    "buffer = StringIO()\n",
    "with redirect_stdout(buffer):\n",
    "    print(\"This is captured\")\n",
    "    print(\"So is this\")\n",
    "\n",
    "print(f\"Captured: {buffer.getvalue()!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Manager Methods\n",
    "\n",
    "| Method | When Called | Purpose |\n",
    "|--------|-------------|--------|\n",
    "| `__enter__` | At `with` start | Setup, return resource |\n",
    "| `__exit__` | At `with` end | Cleanup, handle exceptions |\n",
    "| Return `True` from `__exit__` | | Suppress the exception |\n",
    "| Return `False` from `__exit__` | | Re-raise the exception |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Choosing the Right Concurrency Model\n",
    "\n",
    "| Situation | Solution | Why |\n",
    "|-----------|----------|-----|\n",
    "| CPU-bound, independent tasks | `multiprocessing` | Bypasses GIL |\n",
    "| I/O-bound, few tasks | `threading` | Simple, shared memory |\n",
    "| I/O-bound, many tasks | `asyncio` | Lightweight, scalable |\n",
    "| Mixed workload | Combine them | Use the right tool |\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Module | Key Classes/Functions |\n",
    "|--------|----------------------|\n",
    "| `multiprocessing` | `Pool`, `Process`, `Queue` |\n",
    "| `threading` | `Thread`, `Lock`, `Event` |\n",
    "| `concurrent.futures` | `ThreadPoolExecutor`, `ProcessPoolExecutor` |\n",
    "| `asyncio` | `gather`, `create_task`, `sleep` |\n",
    "| `contextlib` | `contextmanager`, `suppress`, `redirect_stdout` |\n",
    "\n",
    "### Context Manager Patterns\n",
    "\n",
    "| Pattern | Use Case |\n",
    "|---------|----------|\n",
    "| Class-based | Complex setup/teardown |\n",
    "| `@contextmanager` | Simple cases |\n",
    "| `async with` | Async resources |\n",
    "\n",
    "---\n",
    "\n",
    "**Next Module:** Modern Tooling and Packaging - pip, conda, uv, virtual environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plat3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
